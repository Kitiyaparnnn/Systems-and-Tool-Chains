{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question2\n",
    "\n",
    "**Step 1: run the docker compose**\n",
    "\n",
    "**Step 2: open the center control**\n",
    "\n",
    "**Step 3: open a new termial**\n",
    "\n",
    "- run `python producer.py` \n",
    "\n",
    "Refer to producer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "from confluent_kafka import Producer, Consumer, KafkaError\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Kafka settings\n",
    "BROKER = 'localhost:9092'\n",
    "REQUEST_TOPIC = 'youtube_requests'\n",
    "RESPONSE_TOPIC = 'youtube_topic'\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"cmu-key.json\"\n",
    "youtube = build('youtube', 'v3')\n",
    "\n",
    "# Function to create a Kafka producer\n",
    "def create_kafka_producer(broker):\n",
    "    conf = {\n",
    "        'bootstrap.servers': broker,\n",
    "        'client.id': socket.gethostname()\n",
    "    }\n",
    "    return Producer(conf)\n",
    "\n",
    "# Function to create a Kafka consumer\n",
    "def create_kafka_consumer(broker, group_id, topic):\n",
    "    conf = {\n",
    "        'bootstrap.servers': broker,\n",
    "        'group.id': group_id,\n",
    "        'auto.offset.reset': 'earliest',\n",
    "        'client.id': socket.gethostname()\n",
    "    }\n",
    "    consumer = Consumer(conf)\n",
    "    consumer.subscribe([topic])\n",
    "    return consumer\n",
    "\n",
    "# Function to get video data\n",
    "def get_most_popular_videos(video_list):\n",
    "    request = youtube.videos().list(part=\"snippet,statistics\", id=video_list, maxResults=5)\n",
    "    response = request.execute()\n",
    "    videos = []\n",
    "\n",
    "    for item in response.get('items', []):\n",
    "        video_title = item['snippet']['title']\n",
    "        video_like = int(item['statistics'].get('likeCount', 0))\n",
    "        video_id = item['id']\n",
    "        video_data = {\n",
    "            'id': video_id,\n",
    "            'title': video_title,\n",
    "            'likeCount': video_like,\n",
    "        }\n",
    "        videos.append(video_data)\n",
    "\n",
    "    return videos\n",
    "\n",
    "# Main function for producer to process requests\n",
    "def process_requests():\n",
    "    producer = create_kafka_producer(BROKER)\n",
    "    consumer = create_kafka_consumer(BROKER, 'producer_group', REQUEST_TOPIC)\n",
    "\n",
    "    while True:\n",
    "        msg = consumer.poll(timeout=1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            print(f\"Consumer error: {msg.error()}\")\n",
    "            continue\n",
    "\n",
    "        video_list = msg.value().decode('utf-8')\n",
    "        print(f\"Received video list: {video_list}\")\n",
    "\n",
    "        videos = get_most_popular_videos(video_list)\n",
    "        if not videos:\n",
    "            continue\n",
    "\n",
    "        max_like = max(videos, key=lambda item: item['likeCount'])\n",
    "        result = f\"{max_like['id']}; {max_like['title']}; {max_like['likeCount']} likes\"\n",
    "\n",
    "        # Send the response back to the consumer\n",
    "        producer.produce(RESPONSE_TOPIC, key=\"The most popular video\", value=result)\n",
    "        producer.flush()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_requests()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: open a new terminal**\n",
    "\n",
    "- run `streamlit run consumer.py`\n",
    "\n",
    "Refer to consumer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from confluent_kafka import Consumer, Producer, KafkaError\n",
    "import socket\n",
    "import datetime\n",
    "\n",
    "# Kafka settings\n",
    "BROKER = 'localhost:9092'\n",
    "REQUEST_TOPIC = 'youtube_requests'\n",
    "RESPONSE_TOPIC = 'youtube_topic'\n",
    "GROUP_ID = 'analytics'\n",
    "\n",
    "# Function to create a Kafka consumer\n",
    "def create_kafka_consumer(broker, group_id, topic):\n",
    "    conf = {\n",
    "        'bootstrap.servers': broker,\n",
    "        'group.id': group_id,\n",
    "        'auto.offset.reset': 'earliest',\n",
    "        'client.id': socket.gethostname()\n",
    "    }\n",
    "    consumer = Consumer(conf)\n",
    "    consumer.subscribe([topic])\n",
    "    return consumer\n",
    "\n",
    "# Function to create a Kafka producer\n",
    "def create_kafka_producer(broker):\n",
    "    conf = {\n",
    "        'bootstrap.servers': broker,\n",
    "        'client.id': socket.gethostname()\n",
    "    }\n",
    "    return Producer(conf)\n",
    "\n",
    "# Streamlit app\n",
    "def display_kafka_data():\n",
    "    consumer = create_kafka_consumer(BROKER, GROUP_ID, RESPONSE_TOPIC)\n",
    "    producer = create_kafka_producer(BROKER)\n",
    "\n",
    "    st.write(\"Listening to Kafka topic:\", RESPONSE_TOPIC)\n",
    "    input_ids = st.text_input('Enter up to five YouTube video IDs (comma-separated)')\n",
    "    button = st.button(\"Submit\")\n",
    "\n",
    "    if button and input_ids:\n",
    "        # Send request to producer\n",
    "        producer.produce(REQUEST_TOPIC, value=input_ids)\n",
    "        producer.flush()\n",
    "        st.write(\"Request sent. Waiting for response...\")\n",
    "\n",
    "        # Poll for the response\n",
    "        while True:\n",
    "            msg = consumer.poll(timeout=1.0)\n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                st.error(msg.error())\n",
    "                break\n",
    "\n",
    "            key = msg.key().decode('utf-8')\n",
    "            value = msg.value().decode('utf-8').split(';')\n",
    "\n",
    "            # Display the result\n",
    "            st.markdown(f\"ðŸš€ **{key}** \")\n",
    "            st.markdown(f\"**ID:** {value[0]} **Title:** {value[1]}\")\n",
    "            st.markdown(f\"**Likes:** {value[2]}\")\n",
    "            break\n",
    "\n",
    "    consumer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    st.title(\"YouTube Video Popularity Checker\")\n",
    "    display_kafka_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**\n",
    "\n",
    "Refer to q2_1.png, q2_2.png, q2_3.png, q2_4.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reference*\n",
    "\n",
    "- https://docs.streamlit.io/develop/api-reference/widgets/st.text_input\n",
    "- https://developers.google.com/youtube/v3/docs/videos/list\n",
    "- https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html#pythonclient-producer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
