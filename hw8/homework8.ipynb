{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Build a Multi-classifier Machine Learning Model to Switch On/Off Devices\n",
    "using Voice Commands on Raspberry Pi 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q tensorflow tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import shutil, errno\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
      "2428923189/2428923189 [==============================] - 38s 0us/step\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = 'data/'\n",
    "data_dir = pathlib.Path(DATASET_PATH)\n",
    "if not data_dir.exists():\n",
    "    tf.keras.utils.get_file(\n",
    "    'speech_commands.zip',\n",
    "    origin='http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz',\n",
    "    extract=True,\n",
    "    cache_dir='.', cache_subdir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands: ['right' 'eight' 'cat' 'tree' 'backward' 'learn' 'bed' 'happy' 'go'\n",
      " '.DS_Store' 'validation_list.txt' 'LICENSE' 'dog' 'no' 'wow' 'follow'\n",
      " 'nine' 'left' 'stop' 'three' '_background_noise_' 'sheila' 'one' 'bird'\n",
      " 'zero' 'seven' 'up' 'speech_commands.zip' 'visual' 'marvin' 'two' 'house'\n",
      " 'down' 'six' 'yes' 'on' 'testing_list.txt' 'five' 'forward' 'off' 'four']\n"
     ]
    }
   ],
   "source": [
    "# explore labels\n",
    "commands = np.array(tf.io.gfile.listdir(str('data')))\n",
    "commands = commands[commands != 'README.md']\n",
    "print('Commands:', commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split directories for string \"on\", \"off\", \"others\", \"silent\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('data/mydataset')\n",
    "except Exception as e:\n",
    "    print(\"Error creating folder. Error details {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(src, dst):\n",
    "    try:\n",
    "        shutil.copytree(src, dst)\n",
    "    except OSError as exc: # python >2.5\n",
    "        if exc.errno in (errno.ENOTDIR, errno.EINVAL):\n",
    "            shutil.copy(src, dst)\n",
    "        else: raise\n",
    "\n",
    "# directories for on and off\n",
    "copy_data('data/on','data/mydataset/on')\n",
    "copy_data('data/off','data/mydataset/off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories for others\n",
    "os.mkdir('data/mydataset/others')\n",
    "other_labels = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\",\"bed\", \"bird\", \"cat\", \"dog\", \"happy\", \"house\", \"marvin\", \"sheila\", \"tree\", \"wow\"]\n",
    "sample_per_label = 150\n",
    "\n",
    "\n",
    "for label in other_labels:\n",
    "    path = 'data/'+label\n",
    "    f = os.listdir(path)\n",
    "    num_files = len(f)\n",
    "    file_indx = np.arange(num_files)\n",
    "    random.shuffle(file_indx)\n",
    "    for i in range(sample_per_label):\n",
    "        index = file_indx[i]\n",
    "        file_name = f[index]\n",
    "        source = path + '/' + file_name\n",
    "        destination = 'data/mydataset/others/' + file_name\n",
    "        # copy only files\n",
    "        if os.path.isfile(source):\n",
    "            shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for silent\n",
    "os.mkdir('data/mydataset/silent')\n",
    "import scipy\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "fs = 16000\n",
    "num_files = 2400\n",
    "\n",
    "for i in range(num_files):\n",
    "    sample = np.zeros(fs)\n",
    "    filename = str(i*100)+'silent.wav'\n",
    "    sample = sample + 0.01*i*random.randn(fs)\n",
    "    scipy.io.wavfile.write('data/mydataset/silent/'+filename, fs, sample.astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the dataset you used. Organize your data to have the data for each label in a separate folder (as shown in the lecture demo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to mydataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a copy of your pipeline . Customize the parameters as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to q1_1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a screenshot of your Feature Generation Output. Your screenshot should show 1) your name, 2) job completion in green and 3) Feature explorer as shown in the screenshot below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to q1_2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a Screenshot of the output of your classifier. Make sure your screenshot shows the target device, the results of the classification and your name. If you used enough data and reasonable model parameters, it is expected that your modelâ€™s accuracy will be greater than 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to q1_3.png, q1_4.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record a 1-minute video showing the live-classification on your smartphone or your laptop for switching on and off devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reder to [live-classification](https://www.dropbox.com/scl/fi/zpyxsxbbfs489b9foi2gy/live-classification.mov?rlkey=1o9akxg788g8oqgqrhj7quiia&st=pa5r6zps&dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Are you using the most optimal Neural Network architecture for Raspberry\n",
    "Pi 4? Use EON Tuner to validate your answer. Submit a screenshot of the EON Tuner\n",
    "and comment on your findings. Use 100ms target inference time for your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to q2.png\n",
    "\n",
    "The best EON tuner performs 91% accuracy with 1 ms of 100 ms latency. Its model architecture contains 4 convolutional layers with 32, 64, 128, and 256 filters respectively and one dropout layer with 0.5 dropping rate. However, the trained model performance is 93.4% which composes 3 1D-convolutional layers at 8, 16 and 64 filters with dropout in each layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
